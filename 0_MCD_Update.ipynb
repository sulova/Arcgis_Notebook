{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### 1) Copy and Rename MCD older from old version-->new version\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import shutil\n",
    "import os\n",
    "import arcpy\n",
    "\n",
    "# === Set version info ===\n",
    "old_version = \"12\"\n",
    "new_version = \"13\"\n",
    "\n",
    "# === Define paths ===\n",
    "base_path = r\"\\\\WM20ocqu46ph01\\WF_Projects\\DK_THO\\4_OUTPUT\\_MCD\"\n",
    "folder_template = \"005356185-{} - THO - Master Construction Drawing_20250724\"\n",
    "\n",
    "\n",
    "src_folder = os.path.join(base_path, folder_template.format(old_version))\n",
    "dst_folder = os.path.join(base_path, folder_template.format(new_version))\n",
    "\n",
    "# === Step 1: Copy the folder ===\n",
    "try:\n",
    "    shutil.copytree(src_folder, dst_folder)\n",
    "    print(f\"‚úÖ Folder copied from:\\n{src_folder}\\nto:\\n{dst_folder}\")\n",
    "except FileExistsError:\n",
    "    print(f\"‚ö†Ô∏è Destination folder already exists:\\n{dst_folder}\")\n",
    " \n",
    "except FileNotFoundError:\n",
    "    print(f\"‚ùå Source folder not found:\\n{src_folder}\")\n",
    "  \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error copying folder:\\n{e}\")\n",
    "\n",
    "\n",
    "# Rename files inside the copied folder ===\n",
    "renamed_files = 0\n",
    "for root, dirs, files in os.walk(dst_folder):\n",
    "    for filename in files:\n",
    "        print(filename)\n",
    "        # Skip if the file already contains the new version\n",
    "        if f\"-{new_version}\" in filename:\n",
    "            continue\n",
    "        # Proceed if the file contains the old version\n",
    "        if f\"-{old_version}\" in filename:\n",
    "            old_path = os.path.join(root, filename)\n",
    "            new_filename = filename.replace(f\"-{old_version}\", f\"-{new_version}\")\n",
    "            new_path = os.path.join(root, new_filename)\n",
    "            os.rename(old_path, new_path)\n",
    "            renamed_files += 1\n",
    "            print(f\"üîÅ Renamed: {filename} ‚Üí {new_filename}\")\n",
    "\n",
    "print(f\"‚úÖ Finished. {renamed_files} files renamed in folder version {new_version}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### 3) As Built Monopiles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Please complete all steps **before running the script below**:\n",
    "\n",
    "1. üîΩ **Download PDFs**  \n",
    "   - URL: [https://share.jandenul.com/](https://share.jandenul.com/)  \n",
    "   - **Username**: DKTRTI,  **Password**: RKHJEB5LvcnVZw2\n",
    "\n",
    "2. üíæ **Save PDFs** here:  \n",
    "   *\\\\WM20ocqu46ph01\\WF_Projects\\DK_THO\\1_INPUT\\CONSTR\\2025\\20250505 As Built Monopiles from JDN*\n",
    "\n",
    "\n",
    "3. üìã **Extract and copy relevant data** into this Excel file:  \n",
    "   *\\\\WM20ocqu46ph01\\WF_Projects\\DK_THO\\1_INPUT\\CONSTR\\2025\\20250505 As Built Monopiles from JDN\\DK_THO_AsBuilt_Monopile_pt_UTM32N_ta_v0.xlsx*\n",
    "\n",
    "\n",
    "4. üì§ **Export the cleaned data to CSV**: \n",
    "   *\\\\WM20ocqu46ph01\\WF_Projects\\DK_THO\\1_INPUT\\CONSTR\\2025\\20250505 As Built Monopiles from JDN\\DK_THO_AsBuilt_Monopile_pt_UTM32N_ta_v0.csv*\n",
    "   \n",
    "‚ùó **Ensure that the `005356185_THOR_Master_Construction_Drawing.aprx` project is closed** before running the script ‚Äî otherwise layer will be not in the content (run over different aprx or VS code) \n",
    "\n",
    "              Two files will be final ouputs saved in WTG.gdb:\n",
    "              - *DK_THO_AsBuilt_Monopile_pt_UTM32N_pt_v0*\n",
    "              - *DK_THO_AsBuilt_Monopile_OuterDiameter8pt6m_py_UTM32N_pt_v0*\n",
    "              - *DK_THO_AsBuilt_Monopile_pt_UTM32N_pt_v0_Annotation*\n",
    "5. ‚úÖ Run the code\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  üìåAS BUILT - Monopile Location"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change in the code: `new_version = \"XX\"`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import shutil\n",
    "import os\n",
    "import arcpy\n",
    "\n",
    "new_version = \"13\"\n",
    "\n",
    "# === INPUTS ===\n",
    "csv_file = r\"\\\\WM20ocqu46ph01\\WF_Projects\\DK_THO\\1_INPUT\\CONSTR\\2025\\20250505 As Built Monopiles from JDN\\DK_THO_AsBuilt_Monopile_pt_UTM32N_ta_v0.csv\"\n",
    "x_field = \"POS_ASBUILT_EAST\"\n",
    "y_field = \"POS_ASBUILT_NORTH\"\n",
    "spatial_ref = arcpy.SpatialReference(32632)  # UTM Zone 32N\n",
    "\n",
    "# === OUTPUTS ===\n",
    "point_fc = r\"\\\\WM20ocqu46ph01\\WF_Projects\\DK_THO\\2_FINAL\\WTG\\WTG.gdb\\DK_THO_AsBuilt_Monopile_pt_UTM32N_pt_v0\"\n",
    "buffer_fc = r\"\\\\WM20ocqu46ph01\\WF_Projects\\DK_THO\\2_FINAL\\WTG\\WTG.gdb\\DK_THO_AsBuilt_Monopile_OuterDiameter8pt6m_py_UTM32N_pt_v0\"\n",
    "\n",
    "\n",
    "# === STEP 1: Create Point Feature Class ===\n",
    "if arcpy.Exists(point_fc):\n",
    "    arcpy.Delete_management(point_fc)\n",
    "    print(f\"‚úÖ Point feature class was deleted: {point_fc}\")\n",
    "\n",
    "arcpy.management.XYTableToPoint(\n",
    "    in_table=csv_file,\n",
    "    out_feature_class=point_fc,\n",
    "    x_field=x_field,\n",
    "    y_field=y_field,\n",
    "    coordinate_system=spatial_ref\n",
    ")\n",
    "\n",
    "print(f\"‚úÖ Point feature class created: {point_fc}\")\n",
    "\n",
    "# === STEP 2: Create 4.3m Buffer ===\n",
    "if arcpy.Exists(buffer_fc):\n",
    "    arcpy.Delete_management(buffer_fc)\n",
    "    print(f\"‚úÖ Point feature class was deleted: {buffer_fc}\")\n",
    "\n",
    "arcpy.analysis.PairwiseBuffer(\n",
    "    in_features=point_fc,\n",
    "    out_feature_class=buffer_fc,\n",
    "    buffer_distance_or_field=\"4.3 Meters\",\n",
    "    dissolve_option=\"NONE\"\n",
    ")\n",
    "\n",
    "with arcpy.da.UpdateCursor(buffer_fc, ['LAYER']) as cursor:\n",
    "    for row in cursor:\n",
    "        row[0] = 'AS BUILT - Monopile Outer Diameter 8pt6m'\n",
    "        cursor.updateRow(row)\n",
    "\n",
    "print(f\"‚úÖ Buffer feature class created: {buffer_fc}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#####  üìå ANNOTATION ‚Äì As Built Monopile Location - {8-12min}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change in the code: `new_version = \"XX\"`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# === Load the project ===\n",
    "import arcpy\n",
    "\n",
    "new_version = \"13\"\n",
    "\n",
    "# === INPUTS ===\n",
    "aprx_path = r\"\\\\WM20ocqu46ph01\\WF_Projects\\DK_THO\\4_OUTPUT\\_MCD\\005356185_THOR_Master_Construction_Drawing.aprx\"\n",
    "output_gdb = r\"\\\\WM20ocqu46ph01\\WF_Projects\\DK_THO\\2_FINAL\\WTG\\WTG.gdb\"\n",
    "layer_name = \"As Built Monopile\"\n",
    "output_annotation_suffix = \"_Annotation\"\n",
    "new_map_name = f\"005356185-{new_version} THOR Master Construction Drawing CAD\"\n",
    "reference_scale = 100\n",
    "\n",
    "aprx = arcpy.mp.ArcGISProject(aprx_path)\n",
    "target_map = next((m for m in aprx.listMaps() if m.name == new_map_name), None)\n",
    "if not target_map:\n",
    "    raise Exception(f\"‚ùå Map '{new_map_name}' not found.\")\n",
    "print(f\"‚úÖ Map '{new_map_name}' loaded.\")\n",
    "\n",
    "# === Find the layer ===\n",
    "layer = next((lyr for lyr in target_map.listLayers() if lyr.name == layer_name), None)\n",
    "if not layer or not layer.supports(\"SHOWLABELS\"):\n",
    "    raise Exception(f\"‚ùå Layer '{layer_name}' not found or doesn't support labels.\")\n",
    "\n",
    "layer.showLabels = True\n",
    "print(f\"‚úÖ Labels enabled for '{layer_name}'.\")\n",
    "\n",
    "\n",
    "arcpy.cartography.ConvertLabelsToAnnotation(\n",
    "    input_map= target_map,\n",
    "    conversion_scale= 100,\n",
    "    output_geodatabase= output_gdb,\n",
    "    anno_suffix= output_annotation_suffix,\n",
    "    extent='394631.907089481 6223623.59608526 450316.163918058 6267404.33424396 PROJCS[\"WGS_1984_UTM_Zone_32N\",GEOGCS[\"GCS_WGS_1984\",DATUM[\"D_WGS_1984\",SPHEROID[\"WGS_1984\",6378137.0,298.257223563]],PRIMEM[\"Greenwich\",0.0],UNIT[\"Degree\",0.0174532925199433]],PROJECTION[\"Transverse_Mercator\"],PARAMETER[\"False_Easting\",500000.0],PARAMETER[\"False_Northing\",0.0],PARAMETER[\"Central_Meridian\",9.0],PARAMETER[\"Scale_Factor\",0.9996],PARAMETER[\"Latitude_Of_Origin\",0.0],UNIT[\"Meter\",1.0]]',\n",
    "    generate_unplaced=\"GENERATE_UNPLACED\",\n",
    "    require_symbol_id=None,\n",
    "    feature_linked=None,\n",
    "    auto_create=\"AUTO_CREATE\",\n",
    "    update_on_shape_change=\"SHAPE_UPDATE\",\n",
    "    output_group_layer=\"GroupAnno\",\n",
    "    which_layers=\"SINGLE_LAYER\",\n",
    "    single_layer=layer,\n",
    "    multiple_feature_classes=\"FEATURE_CLASS_PER_FEATURE_LAYER\",\n",
    "    merge_label_classes=\"NO_MERGE_LABEL_CLASS\"\n",
    ")\n",
    "\n",
    "\n",
    "# Rename the feature class, if the n\n",
    "annotation_fc = f\"{output_gdb}/As_Built_Monopile{output_annotation_suffix}\"\n",
    "new_ann_fc = f\"{output_gdb}/DK_THO_AsBuilt_Monopile_pt_UTM32N_pt_v0_Annotation\"     \n",
    "\n",
    "if arcpy.Exists(annotation_fc):\n",
    "    print(f\"‚úÖ Annotation feature class saved at: {annotation_fc}\")\n",
    "    if arcpy.Exists(new_ann_fc):\n",
    "        arcpy.Delete_management(new_ann_fc)\n",
    "    arcpy.Rename_management(annotation_fc, new_ann_fc)\n",
    "    print(f\"‚úÖ Renamed annotation feature class to: {new_ann_fc}\")\n",
    "else:\n",
    "    # Print warning if not found\n",
    "    print(f\"‚ö†Ô∏è Annotation feature class NOT found at: {annotation_fc}\")\n",
    "    \n",
    "    \n",
    "\n",
    "# Check if feature class exists\n",
    "if arcpy.Exists(new_ann_fc):\n",
    "    # Add 'Layer' field if it doesn't exist\n",
    "    if \"Layer\" not in [f.name for f in arcpy.ListFields(new_ann_fc)]:\n",
    "        arcpy.AddField_management(new_ann_fc, \"Layer\", \"TEXT\", field_length=255)\n",
    "        print(f\"‚ûï Added missing 'Layer' field to: {new_ann_fc}\")\n",
    "    else:\n",
    "        print(f\"‚ÑπÔ∏è 'Layer' field already exists in: {new_ann_fc}\")\n",
    "    count = 0\n",
    "    with arcpy.da.UpdateCursor(new_ann_fc, [\"Layer\"]) as cursor:\n",
    "        for row in cursor:\n",
    "            if row[0] != \"ANNOTATION - As Built Monopile Location\":\n",
    "                row[0] = \"ANNOTATION - As Built Monopile Location\"\n",
    "                cursor.updateRow(row)\n",
    "                count += 1\n",
    "else:\n",
    "    print(f\"‚ö†Ô∏è Feature class not found: {new_ann_fc}\")\n",
    "    \n",
    "print(\"‚úÖ‚úÖ Layer field values updated **ANNOTATION - As Built Monopile Location** successfully.\")    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4) VESSEL - As Built Footprint - MPI Adventure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Open **EcoCod** and search for the title: *'VAO - Adventure T*'*\n",
    "2) The relevant file from ecodoc should be saved to: `\\\\WM20ocqu46ph01\\WF_Projects\\DK_THO\\1_INPUT\\CONSTR\\2025\\20250604 As Built Secondary Steel Installation from Van Oord`\n",
    "3) Run Code\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  ##### üìåVESSEL - As Built Footprint - MPI  Adventure (Polygon and Annotation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import arcpy\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "# === CONFIGURATION ===\n",
    "ids = [f\"{i:02}\" for i in range(0, 73)]\n",
    "name_polygon = \"DK_THO_MPIAdventure_AsBuiltFootprints_py_UTM32N_v1\"\n",
    "name_ann = \"DK_THO_MPIAdventure_AsBuiltFootprints_Annotation_UTM32N_v1\"\n",
    "\n",
    "spatial_ref = arcpy.SpatialReference(32632)\n",
    "\n",
    "input_dir = r\"\\\\WM20ocqu46ph01\\WF_Projects\\DK_THO\\1_INPUT\\CONSTR\\2025\\20250604 As Built Secondary Steel Installation from Van Oord\"\n",
    "output_gdb = r\"\\\\WM20ocqu46ph01\\WF_Projects\\DK_THO\\2_FINAL\\VESSELS\\VESSELS.gdb\"\n",
    "\n",
    "final_fc_polygon = os.path.join(output_gdb, name_polygon)\n",
    "final_fc_ann = os.path.join(output_gdb, name_ann)\n",
    "\n",
    "export_fc_py = []\n",
    "export_fc_ann= []\n",
    "\n",
    "fields_to_add = [(\"LAYER\", \"TEXT\"), (\"SOURCE\", \"TEXT\"),  (\"NEAR_IF\", \"TEXT\"),(\"WTG_ID\", \"TEXT\")]\n",
    "\n",
    "def sanitize_name(name):\n",
    "    name = os.path.splitext(name)[0]\n",
    "    name = re.sub(r'[^A-Za-z0-9_]', '_', name)\n",
    "    name = re.sub(r'__+', '_', name)\n",
    "    if not re.match(r'^[A-Za-z]', name):\n",
    "        name = \"D_\" + name\n",
    "    return name[:63]\n",
    "\n",
    "# === Process each turbine ID ===\n",
    "for id_ in ids:\n",
    "    wtg_id = f\"T{id_}\"\n",
    "    turbine_folder = os.path.join(input_dir, wtg_id)\n",
    "    for root, dirs, files in os.walk(turbine_folder):\n",
    "        for file in files:\n",
    "            if file.lower().endswith(\".dwg\"):\n",
    "                dwg_path = os.path.join(root, file)\n",
    "                print(f\"‚úÖ {wtg_id} - Processing\")\n",
    "\n",
    "                processing_path = os.path.join(turbine_folder, \"PROCESSING\")\n",
    "                os.makedirs(processing_path, exist_ok=True)\n",
    "                gdb_path = os.path.join(processing_path, f\"DWG_{wtg_id}.gdb\")\n",
    "\n",
    "                # arcpy.Delete_management(gdb_path)\n",
    "                if not arcpy.Exists(gdb_path):\n",
    "                    arcpy.CreateFileGDB_management(processing_path, f\"DWG_{wtg_id}.gdb\")\n",
    "                    name_dwg = sanitize_name(file)\n",
    "                    arcpy.conversion.CADToGeodatabase(dwg_path, gdb_path, name_dwg, \"1000\", \"\")\n",
    "                    print(f\"‚úÖ {wtg_id} - DWG converted to GDB: {gdb_path}\")                 \n",
    "\n",
    "                fc_Polygon = os.path.join(gdb_path, \"Polygon\")    \n",
    "                if not arcpy.Exists(fc_Polygon):\n",
    "                    print(f\"‚ùå {wtg_id} - Polygon feature class not found in GDB.\")\n",
    "                    continue\n",
    "             \n",
    "                # Cleanup fields\n",
    "                fields_fc_Polygon = arcpy.ListFields(fc_Polygon)\n",
    "                fields_to_delete = [f.name for f in fields_fc_Polygon if f.name not in (\"OBJECTID\", \"SHAPE\") and not f.required]\n",
    "                if fields_to_delete:\n",
    "                    arcpy.DeleteField_management(fc_Polygon, fields_to_delete)\n",
    "                    # print(f\"‚úÖ {wtg_id} - Fields are deleting\")\n",
    "                else:\n",
    "                    print(f\"{wtg_id} - No deletable fields in {fc_Polygon}\")\n",
    "\n",
    "                for field_name, ftype in fields_to_add:    \n",
    "                    if field_name not in arcpy.ListFields(fc_Polygon):\n",
    "                        arcpy.AddField_management(fc_Polygon, field_name, ftype)   \n",
    "                # print(f\"‚úÖ {wtg_id} - Adding fields\")\n",
    "                with arcpy.da.UpdateCursor(fc_Polygon, [\"LAYER\", \"SOURCE\",\"NEAR_IF\",\"WTG_ID\"]) as cursor:\n",
    "                    for row in cursor:\n",
    "                        row[0] = \"VESSEL - As Built Footprint - MPI Adventure\"\n",
    "                        row[1] = \"Van Oord / MPI Adventure\"  \n",
    "                        row[2] =  id_                    \n",
    "                        row[3] = 'T'+id_\n",
    "                        cursor.updateRow(row)\n",
    "                export_fc_py.append(fc_Polygon)\n",
    "\n",
    "\n",
    "                fc_Annotation = os.path.join(gdb_path, \"Annotation\")\n",
    "                if not arcpy.Exists(fc_Annotation):\n",
    "                    print(f\"‚ùå {wtg_id} - Annotation feature class not found in GDB.\")\n",
    "                    continue\n",
    "                for field_name, ftype in fields_to_add:    \n",
    "                    if field_name not in arcpy.ListFields(fc_Annotation):\n",
    "                        arcpy.AddField_management(fc_Annotation, field_name, ftype)\n",
    "                with arcpy.da.UpdateCursor(fc_Annotation, [\"LAYER\", \"SOURCE\",\"NEAR_IF\",\"WTG_ID\"]) as cursor:\n",
    "                    for row in cursor:\n",
    "                        row[0] = \"ANNOTATION - As Built Footprint - MPI Adventure\"\n",
    "                        row[1] = \"Van Oord / MPI Adventure\"  \n",
    "                        row[2] =  id_                    \n",
    "                        row[3] = 'T'+id_\n",
    "                        cursor.updateRow(row)\n",
    "                export_fc_ann.append(fc_Annotation)\n",
    "\n",
    "# Annotation\n",
    "if arcpy.Exists(final_fc_ann):\n",
    "    arcpy.Delete_management(final_fc_ann) \n",
    "arcpy.Merge_management(inputs=export_fc_ann, output=final_fc_ann)\n",
    "arcpy.DefineProjection_management(final_fc_ann, spatial_ref)\n",
    "print(f\" ‚úÖ Total Annotation {len(export_fc_ann)} IDs are merged in: {final_fc_ann}\")\n",
    "\n",
    "\n",
    "# Polygon        \n",
    "if arcpy.Exists(final_fc_polygon):\n",
    "    arcpy.Delete_management(final_fc_polygon) \n",
    "arcpy.Merge_management(inputs=export_fc_py, output=final_fc_polygon,)\n",
    "arcpy.DefineProjection_management(final_fc_polygon, spatial_ref)\n",
    "print(f\" ‚úÖ Total {len(export_fc_py)} IDs are merged in: {final_fc_polygon}\")\n",
    "\n",
    "# Final summary\n",
    "fields = [f.name for f in arcpy.ListFields(final_fc_polygon) if f.name and f.type not in ('Geometry', 'OID')]\n",
    "arr = arcpy.da.FeatureClassToNumPyArray(final_fc_polygon, fields)\n",
    "df = pd.DataFrame(arr)\n",
    "print(f\"‚úÖ Loaded positions: {int(len(df) / 6)}\\nWTG_IDs: {df['WTG_ID'].unique()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  \n",
    "  #####  üìåVESSEL - As Built Footprint - MPI  Adventure (Point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ T20 - Processing\n",
      "‚úÖ T23 - Processing\n",
      "‚úÖ T24 - Processing\n",
      "‚úÖ T25 - Processing\n",
      "‚úÖ T26 - Processing\n",
      "‚úÖ T28 - Processing\n",
      "‚úÖ T29 - Processing\n",
      "‚úÖ T34 - Processing\n",
      "‚úÖ T35 - Processing\n",
      "‚úÖ T42 - Processing\n",
      "‚úÖ T43 - Processing\n",
      "‚úÖ T53 - Processing\n",
      "‚úÖ T54 - Processing\n",
      "‚úÖ T55 - Processing\n",
      "‚úÖ T58 - Processing\n",
      "‚úÖ T59 - Processing\n",
      "‚úÖ T60 - Processing\n",
      "‚úÖ T61 - Processing\n",
      "‚úÖ T64 - Processing\n",
      "‚úÖ T68 - Processing\n",
      "‚úÖ T69 - Processing\n",
      "‚úÖ T70 - Processing\n",
      "‚úÖ T71 - Processing\n",
      "‚úÖ Loaded positions: 34\n",
      "WTG_IDs: ['T01' 'T02' 'T03' 'T04' 'T05' 'T06' 'T09' 'T14' 'T15' 'T18' 'T19' 'T20'\n",
      " 'T23' 'T24' 'T25' 'T26' 'T28' 'T29' 'T34' 'T35' 'T42' 'T43' 'T53' 'T54'\n",
      " 'T55' 'T58' 'T59' 'T60' 'T61' 'T64' 'T68' 'T69' 'T70' 'T71']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import arcpy\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "# === CONFIGURATION ===\n",
    "# ids = ['01']\n",
    "# ids = ['01','64', '35','71','58','25','60','29']\n",
    "ids = [f\"{i:02}\" for i in range(1, 73)]\n",
    "name_pt = \"DK_THO_MPIAdventure_AsBuiltFootprints_pt_UTM32N_v1\"\n",
    "\n",
    "input_dir = r\"\\\\WM20ocqu46ph01\\WF_Projects\\DK_THO\\1_INPUT\\CONSTR\\2025\\20250604 As Built Secondary Steel Installation from Van Oord\"\n",
    "output_gdb = r\"\\\\WM20ocqu46ph01\\WF_Projects\\DK_THO\\2_FINAL\\VESSELS\\VESSELS.gdb\"\n",
    "\n",
    "spatial_ref = arcpy.SpatialReference(32632)\n",
    "\n",
    "final_fc_point = os.path.join(output_gdb, name_pt)\n",
    "export_fcs_pt = []\n",
    "\n",
    "fields_to_add = [(\"LAYER\", \"TEXT\"), (\"SOURCE\", \"TEXT\"),  (\"NEAR_IF\", \"TEXT\"),(\"WTG_ID\", \"TEXT\")]\n",
    "\n",
    "def sanitize_name(name):\n",
    "    name = os.path.splitext(name)[0]\n",
    "    name = re.sub(r'[^A-Za-z0-9_]', '_', name)\n",
    "    name = re.sub(r'__+', '_', name)\n",
    "    if not re.match(r'^[A-Za-z]', name):\n",
    "        name = \"D_\" + name\n",
    "    return name[:63]\n",
    "\n",
    "# === Process each turbine ID ===\n",
    "for id_ in ids:\n",
    "    wtg_id = f\"T{id_}\"\n",
    "    turbine_folder = os.path.join(input_dir, wtg_id)\n",
    "    for root, dirs, files in os.walk(turbine_folder):\n",
    "        for file in files:\n",
    "            if file.lower().endswith(\".dwg\"):\n",
    "                dwg_path = os.path.join(root, file)\n",
    "                print(f\"‚úÖ {wtg_id} - Processing\")\n",
    "\n",
    "                processing_path = os.path.join(turbine_folder, \"PROCESSING\")\n",
    "                os.makedirs(processing_path, exist_ok=True)\n",
    "                gdb_path = os.path.join(processing_path, f\"DWG_{wtg_id}.gdb\")\n",
    "                \n",
    "                #arcpy.Delete_management(gdb_path)\n",
    "                if not arcpy.Exists(gdb_path):\n",
    "                    arcpy.CreateFileGDB_management(processing_path, f\"DWG_{wtg_id}.gdb\")\n",
    "                    name_dwg = sanitize_name(file)\n",
    "                    arcpy.conversion.CADToGeodatabase(dwg_path, gdb_path, name_dwg, \"1000\", \"\")\n",
    "                    print(f\"‚úÖ {wtg_id} - DWG converted to GDB\")                 \n",
    "\n",
    "                fc = os.path.join(gdb_path, \"Point\")\n",
    "                if not arcpy.Exists(fc):\n",
    "                    print(f\"‚ùå {wtg_id} - Point feature class not found in GDB.\")\n",
    "                    continue\n",
    "              \n",
    "                # Cleanup fields\n",
    "                fields_in_fcs = arcpy.ListFields(fc)\n",
    "\n",
    "                fields_to_delete = [f.name for f in fields_in_fcs if f.name not in (\"OBJECTID\", \"SHAPE\", \"RefName\", \"Angle\", \"LEG_PEN1\", \"VESSEL1\", \"DATE1\") and not f.required]\n",
    "\n",
    "                if fields_to_delete:\n",
    "                    arcpy.DeleteField_management(fc, fields_to_delete)\n",
    "                    # print(f\"‚úÖ {wtg_id} - Fields are deleting\")\n",
    "                else:\n",
    "                    print(f\"{wtg_id} - No deletable fields in {fc}\")\n",
    "\n",
    "                for field_name, ftype in fields_to_add:    \n",
    "                    if field_name not in arcpy.ListFields(fc):\n",
    "                        arcpy.AddField_management(fc, field_name, ftype)\n",
    "                    \n",
    "                # print(f\"‚úÖ {wtg_id} - Adding fields\")\n",
    "\n",
    "                with arcpy.da.UpdateCursor(fc, [\"LAYER\", \"SOURCE\",\"NEAR_IF\",\"WTG_ID\"]) as cursor:\n",
    "                    for row in cursor:\n",
    "                        row[0] = \"VESSEL - As Built Footprint - MPI Adventure Point\"\n",
    "                        row[1] = \"Van Oord / MPI Adventure\"  \n",
    "                        row[2] =  id_                    \n",
    "                        row[3] = 'T'+id_\n",
    "                        cursor.updateRow(row)\n",
    "\n",
    "                                # Fields to update\n",
    "                fields = [\"LEG_PEN1\", \"VESSEL1\", \"DATE1\"]\n",
    "\n",
    "                # Cleanup temp layers\n",
    "                has_vals_name = f\"has_vals_{wtg_id}\"\n",
    "                null_vals_name = f\"null_vals_{wtg_id}\"\n",
    "                near_tbl = f\"in_memory/near_{wtg_id}\"\n",
    "\n",
    "                # Clean up if they already exist\n",
    "                for temp in [has_vals_name, null_vals_name, near_tbl]:\n",
    "                    if arcpy.Exists(temp):\n",
    "                        arcpy.Delete_management(temp)\n",
    "\n",
    "                # Make layers\n",
    "                has_vals = arcpy.MakeFeatureLayer_management(fc, has_vals_name, \" AND \".join([f\"{f} IS NOT NULL\" for f in fields]))\n",
    "                null_vals = arcpy.MakeFeatureLayer_management(fc, null_vals_name, \" OR \".join([f\"{f} IS NULL\" for f in fields]))\n",
    "\n",
    "                # Generate near table\n",
    "                arcpy.analysis.GenerateNearTable(null_vals, has_vals, near_tbl, closest=True)\n",
    "\n",
    "                # Create lookups\n",
    "                val_lookup = {r[0]: r[1:] for r in arcpy.da.SearchCursor(has_vals, [\"OID@\"] + fields)}\n",
    "                near_map = {r[0]: r[1] for r in arcpy.da.SearchCursor(near_tbl, [\"IN_FID\", \"NEAR_FID\"])}\n",
    "\n",
    "                # Update nulls using nearest values\n",
    "                with arcpy.da.UpdateCursor(null_vals, [\"OID@\"] + fields) as cursor:\n",
    "                    for row in cursor:\n",
    "                        donor = val_lookup.get(near_map.get(row[0]))\n",
    "                        if donor:\n",
    "                            row[1:] = [donor[i] if not row[i+1] else row[i+1] for i in range(len(fields))]\n",
    "                            cursor.updateRow(row)\n",
    "\n",
    "                export_fcs_pt.append(fc)\n",
    "        \n",
    "if arcpy.Exists(final_fc_point):\n",
    "    arcpy.Delete_management(final_fc_point) \n",
    "\n",
    "arcpy.Merge_management(inputs=export_fcs_pt, output=final_fc_point)\n",
    "arcpy.DefineProjection_management(final_fc_point, spatial_ref)\n",
    "\n",
    "# Delete features where Angle = 0\n",
    "if \"Angle\" in [f.name for f in arcpy.ListFields(final_fc_point)]:\n",
    "    layer_name = \"in_memory\\\\angle_layer\"\n",
    "    arcpy.management.MakeFeatureLayer(final_fc_point, layer_name)\n",
    "    arcpy.management.SelectLayerByAttribute(layer_name, \"NEW_SELECTION\", '\"Angle\" = 0')\n",
    "    arcpy.management.DeleteFeatures(layer_name)\n",
    "\n",
    "# Final summary\n",
    "fields = [f.name for f in arcpy.ListFields(final_fc_point) if f.name and f.type not in ('Geometry', 'OID')]\n",
    "arr = arcpy.da.FeatureClassToNumPyArray(final_fc_point, fields)\n",
    "df = pd.DataFrame(arr)\n",
    "print(f\"‚úÖ Loaded positions: {int(len(df) / 6)}\\nWTG_IDs: {df['WTG_ID'].unique()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  #####  üìåVESSEL - Ghost Position Sector - MPI Adventure - VOOW - LEGS_PRESENT Field Update\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " This script performs a spatial join to identify which sector polygons contain MPI Adventure footprint points, then updates the LEGS_PRESENT field in the sector feature class to \"Yes\" for those sectors that contain at least one point.\n",
    "\n",
    "üõ†Ô∏è LEGS_PRESENT field in the **sector feature class** (DK_THO_MPIAdventure_VesselGhostPositioningSectors_py_UTM32N_v2) has the query:\n",
    "- 'LEGS_PRESENT = NO':\n",
    "  - ‚úÖ `LEGS_PRESENT = 'Yes'` ‚Äî if the sector contains **MPI footprint point**  \n",
    "  -  ‚ùå `LEGS_PRESENT = 'No'` ‚Äî if the sector contains **no points**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sectors with points (footprints of sst): 34\n",
      "  LEGS_PRESENT  Count\n",
      "0           No     67\n",
      "1          Yes     58\n"
     ]
    }
   ],
   "source": [
    "import arcpy\n",
    "import pandas as pd\n",
    "\n",
    "# Inputs\n",
    "points = r\"\\\\WM20ocqu46ph01\\WF_Projects\\DK_THO\\2_FINAL\\VESSELS\\VESSELS.gdb\\DK_THO_MPIAdventure_AsBuiltFootprints_pt_UTM32N_v1\"\n",
    "sectors = r\"\\\\WM20ocqu46ph01\\WF_Projects\\DK_THO\\2_FINAL\\VESSELS\\VESSELS.gdb\\DK_THO_MPIAdventure_VesselGhostPositioningSectors_py_UTM32N_v2\"\n",
    "update_field = \"LEGS_PRESENT\"\n",
    "\n",
    "# Temporary in-memory join result\n",
    "intersect_layer = \"in_memory\\\\point_sector_intersect\"\n",
    "\n",
    "# Delete if already exists\n",
    "if arcpy.Exists(intersect_layer):\n",
    "    arcpy.Delete_management(intersect_layer)\n",
    "\n",
    "# Perform spatial join\n",
    "arcpy.analysis.SpatialJoin(\n",
    "    target_features=sectors,\n",
    "    join_features=points,\n",
    "    out_feature_class=intersect_layer,\n",
    "    join_operation=\"JOIN_ONE_TO_ONE\",\n",
    "    join_type=\"KEEP_ALL\",\n",
    "    match_option=\"INTERSECT\"\n",
    ")\n",
    "\n",
    "# Build a set of sectors that have Join_Count > 0\n",
    "intersect_ids = set()\n",
    "with arcpy.da.SearchCursor(intersect_layer, [\"TARGET_FID\", \"Join_Count\"]) as cursor:\n",
    "    for target_fid, join_count in cursor:\n",
    "        if join_count > 0:\n",
    "            intersect_ids.add(target_fid)\n",
    "\n",
    "# Debug: print counts\n",
    "print(f\"Sectors with points (footprints of sst): {len(intersect_ids)}\")\n",
    "\n",
    "# Update sectors accordingly\n",
    "with arcpy.da.UpdateCursor(sectors, [\"OBJECTID\", update_field]) as cursor:\n",
    "    for row in cursor:\n",
    "        row[1] = \"Yes\" if row[0] in intersect_ids else \"No\"\n",
    "        cursor.updateRow(row)\n",
    "\n",
    "# Step 2: Read WTGID and LEGS_PRESENT for all sectors\n",
    "wtgid_field = \"WTGID\"\n",
    "fields = [wtgid_field, update_field]\n",
    "\n",
    "wtgid_status = {}\n",
    "\n",
    "with arcpy.da.SearchCursor(sectors, fields) as cursor:\n",
    "    for wtgid, legs_present in cursor:\n",
    "        if wtgid not in wtgid_status:\n",
    "            wtgid_status[wtgid] = False\n",
    "        if legs_present == \"Yes\":\n",
    "            wtgid_status[wtgid] = True  # Mark this WTGID as having at least one \"Yes\"\n",
    "\n",
    "# Step 3: Update all sectors based on group status\n",
    "with arcpy.da.UpdateCursor(sectors, [wtgid_field, update_field]) as cursor:\n",
    "    for wtgid, legs_present in cursor:\n",
    "        new_value = \"Yes\" if wtgid_status.get(wtgid, False) else \"No\"\n",
    "        if legs_present != new_value:\n",
    "            cursor.updateRow([wtgid, new_value])\n",
    "\n",
    "\n",
    "# Load updated sectors to numpy array and then pandas DataFrame\n",
    "fields = [f.name for f in arcpy.ListFields(sectors) if f.name and f.type not in ('Geometry', 'OID')]\n",
    "arr = arcpy.da.FeatureClassToNumPyArray(sectors, fields)\n",
    "df = pd.DataFrame(arr)\n",
    "\n",
    "# Print count summary of Yes and No\n",
    "summary = df['LEGS_PRESENT'].value_counts(dropna=False).rename_axis('LEGS_PRESENT').reset_index(name='Count')\n",
    "print(summary)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5) Armour Layer - Raster Mosaic Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Ask Dele to get a SHP file from JDN and save them to:` \\\\WM20ocqu46ph01\\WF_Projects\\DK_THO\\1_INPUT\\CONSTR\\2025\\20250725 As Built Armour Layer Installation From JDN\\Outlines\\Outlines`\n",
    "2. Run Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### üìåAS BUILT - Armour Layer Extent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing shapefile: JDN7723-SUR-BI-PST_AR_CONTOURS-T08.shp with WTG = T08\n",
      "Processing shapefile: JDN7723-SUR-BI-PST_AR_CONTOURS-T10.shp with WTG = T10\n",
      "Processing shapefile: JDN7723-SUR-BI-PST_AR_CONTOURS-T11.shp with WTG = T11\n",
      "Processing shapefile: JDN7723-SUR-BI-PST_AR_CONTOURS-T12.shp with WTG = T12\n",
      "Processing shapefile: JDN7723-SUR-BI-PST_AR_CONTOURS-T17.shp with WTG = T17\n",
      "Processing shapefile: JDN7723-SUR-BI-PST_AR_CONTOURS-T22.shp with WTG = T22\n",
      "Processing shapefile: JDN7723-SUR-BI-PST_AR_CONTOURS-T27.shp with WTG = T27\n",
      "Processing shapefile: JDN7723-SUR-BI-PST_AR_CONTOURS-T30.shp with WTG = T30\n",
      "Processing shapefile: JDN7723-SUR-BI-PST_AR_CONTOURS-T32.shp with WTG = T32\n",
      "Processing shapefile: JDN7723-SUR-BI-PST_AR_CONTOURS-T33.shp with WTG = T33\n",
      "Processing shapefile: JDN7723-SUR-BI-PST_AR_CONTOURS-T36.shp with WTG = T36\n",
      "Processing shapefile: JDN7723-SUR-BI-PST_AR_CONTOURS-T45.shp with WTG = T45\n",
      "Processing shapefile: JDN7723-SUR-BI-PST_AR_CONTOURS-T47.shp with WTG = T47\n",
      "Processing shapefile: JDN7723-SUR-BI-PST_AR_CONTOURS-T49.shp with WTG = T49\n",
      "Processing shapefile: JDN7723-SUR-BI-PST_AR_CONTOURS-T51.shp with WTG = T51\n",
      "Processing shapefile: JDN7723-SUR-BI-PST_AR_CONTOURS-T62.shp with WTG = T62\n",
      "‚úÖ Successfully merged into: \\\\WM20ocqu46ph01\\WF_Projects\\DK_THO\\2_FINAL\\CONSTR\\CONSTR.gdb\\DK_THO_ArmourLayer_AsBuiltExtent_py_UTM32N_v0\n"
     ]
    }
   ],
   "source": [
    "import arcpy\n",
    "import os\n",
    "import re\n",
    "\n",
    "# Set workspace and folders\n",
    "root_folder = r\"\\\\WM20ocqu46ph01\\WF_Projects\\DK_THO\\1_INPUT\\CONSTR\\2025\\20250725 As Built Armour Layer Installation From JDN\\Outlines\\Outlines\"\n",
    "final_gdb = r\"\\\\WM20ocqu46ph01\\WF_Projects\\DK_THO\\2_FINAL\\CONSTR\\CONSTR.gdb\"\n",
    "arcpy.env.workspace = root_folder\n",
    "arcpy.env.overwriteOutput = True\n",
    "\n",
    "shapefiles_to_merge = []\n",
    "\n",
    "# Loop through directories and find all shapefiles\n",
    "for dirpath, dirnames, filenames in os.walk(root_folder):\n",
    "    for filename in filenames:\n",
    "        if filename.lower().endswith(\".shp\"):\n",
    "            shp_path = os.path.join(dirpath, filename)\n",
    "\n",
    "            # Extract TXX from filename using regex\n",
    "            match = re.search(r'(T\\d{2})', filename)\n",
    "            wtg_value = match.group(1) if match else \"UNKNOWN\"\n",
    "            print(f\"Processing shapefile: {filename} with WTG = {wtg_value}\")\n",
    "\n",
    "            # Add WTG field if it does not exist\n",
    "            field_names = [f.name for f in arcpy.ListFields(shp_path)]\n",
    "            if \"WTG\" not in field_names:\n",
    "                arcpy.AddField_management(shp_path, \"WTG\", \"TEXT\", field_length=10)\n",
    "\n",
    "            # Populate WTG field\n",
    "            with arcpy.da.UpdateCursor(shp_path, [\"WTG\"]) as cursor:\n",
    "                for row in cursor:\n",
    "                    row[0] = wtg_value\n",
    "                    cursor.updateRow(row)\n",
    "\n",
    "            shapefiles_to_merge.append(shp_path)\n",
    "\n",
    "# Output merged feature class\n",
    "output_ArmourLayer = os.path.join(final_gdb, \"DK_THO_ArmourLayer_AsBuiltExtent_py_UTM32N_v0\")\n",
    "\n",
    "# Merge all shapefiles\n",
    "if shapefiles_to_merge:\n",
    "    arcpy.Merge_management(shapefiles_to_merge, output_ArmourLayer)\n",
    "    print(f\"‚úÖ Successfully merged into: {output_ArmourLayer}\")\n",
    "\n",
    "    # Add LAYER, SOURSE, DOC fields to the merged feature class\n",
    "    fields_to_add = [\n",
    "        (\"LAYER\", \"TEXT\", \"CONSTRUCTION - Armour Layer As Built Extent\"),\n",
    "        (\"SOURCE\", \"TEXT\", \"JDN\"),\n",
    "        (\"DOC\", \"TEXT\", root_folder)\n",
    "    ]\n",
    "\n",
    "    existing_fields = [f.name for f in arcpy.ListFields(output_ArmourLayer)]\n",
    "\n",
    "    for field_name, field_type, _ in fields_to_add:\n",
    "        if field_name not in existing_fields:\n",
    "            arcpy.AddField_management(output_ArmourLayer, field_name, field_type, field_length=255)\n",
    "\n",
    "    # Update the values in the new fields\n",
    "    with arcpy.da.UpdateCursor(output_ArmourLayer, [f[0] for f in fields_to_add]) as cursor:\n",
    "        for row in cursor:\n",
    "            for i, (_, _, value) in enumerate(fields_to_add):\n",
    "                row[i] = value\n",
    "            cursor.updateRow(row)\n",
    "\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è No shapefiles found to merge.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### üìåARMOUR RASTER MOSAIC DATASET"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) [Download Raster data from this SharePoint folder](https://rwe.sharepoint.com/teams/ThorScourProtectionOffshoreExecution/Shared%20Documents/Forms/AllItems.aspx?csf=1&web=1&e=9bvbjG&FolderCTID=0x01200039B049B06B30784BAE472FE9C6E0D5FD&id=%2Fteams%2FThorScourProtectionOffshoreExecution%2FShared%20Documents%2FScour%20Protection%20Offshore%20Execution%2FLocation%20In%20Out%20Surveys%2F02%20Post%2Dsurveys)\n",
    "2. Save them to:`\\\\WM20ocqu46ph01\\WF_Projects\\DK_THO\\1_INPUT\\CONSTR\\2025\\20250725 As Built Armour Layer Installation From JDN\\OneDrive_2025-07-28\\02 Post-surveys`\n",
    "\n",
    "- Information:[Combining Mosaics into a single Image Service](https://rwe-renewables.atlassian.net/wiki/spaces/GISPORTAL/pages/636782242/Combining+Mosaics+into+a+single+Image+Service)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì¶ Creating Mosaic Dataset: \\\\WM20ocqu46ph01\\WF_Projects\\DK_THO\\2_FINAL\\CONSTR\\CONSTR.gdb\\DK_THO_AsBuilt_ArmourLayer_ra_UTM32N_v0\n",
      "‚ûï Adding PRE rasters to: DK_THO_AsBuilt_ArmourLayer_ra_UTM32N_v0\n",
      "üìù Tagging ProductName as DK_THO_AsBuilt_ArmourLayer_PreSurvey_ra_UTM32N_v0\n",
      "‚ûï Adding PRE rasters to: DK_THO_AsBuilt_ArmourLayer_ra_UTM32N_v0\n",
      "üìù Tagging ProductName as DK_THO_AsBuilt_ArmourLayer_PostSurvey_ra_UTM32N_v0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import arcpy\n",
    "\n",
    "# --- USER CONFIGURATION ---\n",
    "base_dir = r\"\\\\WM20ocqu46ph01\\WF_Projects\\DK_THO\\1_INPUT\\CONSTR\\2025\\20250725 As Built Armour Layer Installation From JDN\\OneDrive_2025-07-28\\02 Post-surveys\"\n",
    "final_gdb = r\"\\\\WM20ocqu46ph01\\WF_Projects\\DK_THO\\2_FINAL\\CONSTR\\CONSTR.gdb\"\n",
    "\n",
    "mosaic_name = \"DK_THO_AsBuilt_ArmourLayer_ra_UTM32N_v0\"\n",
    "product_name_PRE = \"DK_THO_AsBuilt_ArmourLayer_PreSurvey_ra_UTM32N_v0\"\n",
    "product_name_PST = \"DK_THO_AsBuilt_ArmourLayer_PostSurvey_ra_UTM32N_v0\"\n",
    "spatial_ref = arcpy.SpatialReference(32632)\n",
    "\n",
    "arcpy.env.workspace = final_gdb\n",
    "mosaic_path = os.path.join(final_gdb, mosaic_name)\n",
    "\n",
    "# Delete existing mosaic dataset if it exists\n",
    "if arcpy.Exists(mosaic_path):\n",
    "    print(f\"üóëÔ∏è Deleting existing Mosaic Dataset: {mosaic_path}\")\n",
    "    arcpy.Delete_management(mosaic_path)\n",
    "\n",
    "# Create mosaic dataset\n",
    "print(f\"üì¶ Creating Mosaic Dataset: {mosaic_path}\")\n",
    "arcpy.CreateMosaicDataset_management(\n",
    "    final_gdb,\n",
    "    mosaic_name,\n",
    "    spatial_ref,\n",
    "    product_definition=\"NONE\",\n",
    ")\n",
    "\n",
    "\n",
    "# --- Add PRE rasters ---\n",
    "print(f\"‚ûï Adding PRE rasters to: {mosaic_name}\")\n",
    "arcpy.AddRastersToMosaicDataset_management(\n",
    "    in_mosaic_dataset=mosaic_name,\n",
    "    raster_type=\"Raster Dataset\",\n",
    "    input_path=base_dir,\n",
    "    filter=\"*PRE*.tif\",\n",
    "    update_cellsize_ranges=\"UPDATE_CELL_SIZES\",\n",
    "    update_boundary=\"UPDATE_BOUNDARY\",\n",
    "    update_overviews=\"NO_OVERVIEWS\",\n",
    "    sub_folder=\"SUBFOLDERS\",\n",
    "    duplicate_items_action=\"ALLOW_DUPLICATES\",\n",
    "    build_pyramids=\"BUILD_PYRAMIDS\",\n",
    "    calculate_statistics=\"CALCULATE_STATISTICS\",\n",
    "    build_thumbnails=\"NO_THUMBNAILS\",\n",
    "    estimate_statistics=\"ESTIMATE_STATISTICS\",\n",
    "    enable_pixel_cache=\"NO_PIXEL_CACHE\"\n",
    ")\n",
    "\n",
    "# Tag ProductName for PRE rasters\n",
    "print(f\"üìù Tagging ProductName as {product_name_PRE}\")\n",
    "with arcpy.da.UpdateCursor(mosaic_name, [\"Category\", \"ProductName\"]) as cursor:\n",
    "    for row in cursor:\n",
    "        if row[0] == 1:\n",
    "            row[1] = product_name_PRE\n",
    "            cursor.updateRow(row)\n",
    "\n",
    "# --- Add PRE rasters ---\n",
    "print(f\"‚ûï Adding PRE rasters to: {mosaic_name}\")\n",
    "arcpy.AddRastersToMosaicDataset_management(\n",
    "    in_mosaic_dataset=mosaic_name,\n",
    "    raster_type=\"Raster Dataset\",\n",
    "    input_path=base_dir,\n",
    "    filter=\"*PST*.tif\",\n",
    "    update_cellsize_ranges=\"UPDATE_CELL_SIZES\",\n",
    "    update_boundary=\"UPDATE_BOUNDARY\",\n",
    "    update_overviews=\"NO_OVERVIEWS\",\n",
    "    sub_folder=\"SUBFOLDERS\",\n",
    "    duplicate_items_action=\"ALLOW_DUPLICATES\",\n",
    "    build_pyramids=\"BUILD_PYRAMIDS\",\n",
    "    calculate_statistics=\"CALCULATE_STATISTICS\",\n",
    "    build_thumbnails=\"NO_THUMBNAILS\",\n",
    "    estimate_statistics=\"ESTIMATE_STATISTICS\",\n",
    "    enable_pixel_cache=\"NO_PIXEL_CACHE\"\n",
    ")\n",
    "\n",
    "# Tag ProductName for PRE rasters\n",
    "print(f\"üìù Tagging ProductName as {product_name_PST}\")\n",
    "with arcpy.da.UpdateCursor(mosaic_name, [\"Category\", \"ProductName\"]) as cursor:\n",
    "    for row in cursor:\n",
    "        if row[0] == 1 and (row[1] is None or str(row[1]).strip() == \"\"):\n",
    "            row[1] = product_name_PST\n",
    "            cursor.updateRow(row)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6)  AutoCAD Update\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üõ†Ô∏è AutoCAD Update Instructions\n",
    "- Every new layer must include a **Layer** field in the attribute table to ensure compatibility between **ArcGIS Pro and AutoCAD**.  \n",
    "- Layer names in the attribute table should **match the entries** in the **Excel log file** for traceability and consistency.\n",
    "\n",
    "---\n",
    " üîπ Preparing the DWG for Export\n",
    "\n",
    "1. **Open the DWG file** and delete existing layers that will be replaced.  \n",
    "   - Use the AutoCAD command:  \n",
    "     LAYDEL ‚Üí Enter ‚Üí Type N ‚Üí Enter ‚Üí Select layers by name\n",
    "     \n",
    "   - ‚ö†Ô∏è **Warning**: LAYDEL permanently deletes the selected layers and all objects on them. Use with caution.\n",
    "\n",
    "   **Example layers to delete:**\n",
    "   - ANNOTATION - As Built Footprint - MPI Adventure`\n",
    "   - ANNOTATION - As Built Monopile Location`\n",
    "   - VESSEL - As Built Footprint - MPI Adventure`\n",
    "   - AS BUILT - Monopile Location`\n",
    "   - AS BUILT - Monopile Outer Diameter 8pt6m`\n",
    "   \n",
    "\n",
    "2. **Save the DWG file** after cleanup.\n",
    "\n",
    "---\n",
    "\n",
    " üîπ Exporting Updated Data from ArcGIS Pro\n",
    "\n",
    "3. **Open the ArcGIS project MAP:* 005356185-{new version} THOR Master Construction Drawing CAD* that contains the new layers\n",
    "\n",
    "\n",
    "4. Use the **Export to CAD** geoprocessing tool:\n",
    "   - Ensure only required NEW layers are selected for export.Layers are new in ArcGIS Pro.\n",
    " \n",
    "\n",
    "5. **Remove non-essential layers** that should not be included in the export:\n",
    "   - For example:  `Bathymetry raster` (use contours instead of raster for CAD exports)\n",
    "\n",
    "6. Use the **Append** option to add data to the existing DWG file without overwriting unrelated content.\n",
    "\n",
    "7. Export the **.aprx** as a **Project Package**, ensuring that excluded `Bathymetry` are not part of the package.\n",
    "\n",
    "#### üó∫Ô∏è Annotations: \n",
    "1:25000 scale when exporting WTG Layout annotation. below is the layer link for future reference:\\\\WM20ocqu46ph01\\WF_Projects\\DK_THO\\0_ARCPRO\\LAYER FILES\\DK_THO_Layout_pt_UTM32N_v8.lyrx\n",
    "\n",
    "#### CAD Tips:\n",
    "1) üîç Zoom to Layer \n",
    "      - Type QSELECT ‚Üí Enter, Set Property = Layer, and choose your layer --> OK \n",
    "      - Zoom to Selection: -Type Z ‚Üí Enter--> Type O (for Object) ‚Üí Enter\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  8) üó∫Ô∏è Export Map Package Workflow"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Change in the code: `new_version = \"XX\"`) \n",
    "2) Run the code\n",
    "3) Check output folder MCD_SCRATCH--> 01_ConsolidatedPackage and Open Map\n",
    "4) Run tool`\"Package Project\"`-->  setting: Share outside of organization, History not included, All versions\n",
    "      - ‚úÖ Ensure *Bathy* and *MBES* layers are not included \n",
    "      - ‚úÖ Check that data sources are correctly linked to the GDB (Geodatabase), etc.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import arcpy\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "new_version = 13\n",
    "\n",
    "project_path = r\"\\\\WM20ocqu46ph01\\WF_Projects\\DK_THO\\4_OUTPUT\\_MCD\\005356185_THOR_Master_Construction_Drawing.aprx\"\n",
    "output_folder = r\"\\\\WM20ocqu46ph01\\WF_Projects\\DK_THO\\4_OUTPUT\\_MCD\\MCD_SCRATCH\\01_ConsolidatedPackage\"\n",
    "temp_aprx_path = r\"\\\\WM20ocqu46ph01\\WF_Projects\\DK_THO\\4_OUTPUT\\_MCD\\TempProject.aprx\"\n",
    "map_name = f\"005356185-{new_version} THOR Master Construction Drawing CAD\"\n",
    "\n",
    "if os.path.exists(temp_aprx_path):\n",
    "    os.remove(temp_aprx_path)\n",
    "\n",
    "shutil.copyfile(project_path, temp_aprx_path)\n",
    "\n",
    "aprx = arcpy.mp.ArcGISProject(temp_aprx_path)\n",
    "\n",
    "maps = aprx.listMaps(map_name)\n",
    "if not maps:\n",
    "    raise ValueError(f\"Map '{map_name}' not found in project.\")\n",
    "map_obj = maps[0]\n",
    "\n",
    "\n",
    "layers_to_exclude = [\n",
    "    \"Bathymetry Fugro 2023\",\n",
    "    \"MBES Bathymetry (2023), mbMSL (Fugro 2023 UXO Survey - 004896869-01)\",\n",
    "    \"Nearshore Bathymetry - 004896852-02-FUGG - THOR 2023 LIDAR SURVEY REPORT\",\n",
    "    \"Hillshade\",\n",
    "    \"Hillshade Nearshore\"\n",
    "]\n",
    "\n",
    "for layer in map_obj.listLayers():\n",
    "    try:\n",
    "        if hasattr(layer, 'name') and layer.name in layers_to_exclude:\n",
    "            print(f\"üóëÔ∏è Removed layer: {layer.name}\")\n",
    "            map_obj.removeLayer(layer)\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Skipped a layer due to an error: {e}\")\n",
    "\n",
    "# Get the remaining map (should be only one now)\n",
    "target_map = next((m for m in aprx.listMaps() if m.name == map_name), None)\n",
    "if target_map is None:\n",
    "    raise ValueError(f\"Map '{map_name}' not found in the temp project.\")\n",
    "\n",
    "output = os.path.join(output_folder, map_name.replace(\":\", \"_\"))  # Clean name\n",
    "\n",
    "arcpy.management.ConsolidateMap(\n",
    "    in_map=map_obj,\n",
    "    output_folder=output,\n",
    "    convert_data=\"CONVERT\",\n",
    "    convert_arcsde_data=\"PRESERVE_ARCSDE\",\n",
    "    extent=\"DEFAULT\",\n",
    "    apply_extent_to_arcsde=\"ALL\",\n",
    "    preserve_sqlite=\"CONVERT_SQLITE\",\n",
    "    select_related_rows=\"KEEP_ALL_RELATED_ROWS\"\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8) üåê Portal Update Instructions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üìÅ Open ArcGIS Project\n",
    "*\\\\WM20ocqu46ph01\\WF_Projects\\DK_THO\\4_OUTPUT\\_MCD\\005356185_THOR_Master_Construction_Drawing.aprx*\n",
    "\n",
    "üó∫Ô∏è Open the Map: - 005356185 THOR Master Construction Drawing Portal\n",
    "\n",
    "üìÇ Manage Versions: - Move the previous version to the Approved group. - Move the new version to the Under Review group\n",
    "\n",
    "‚ûï Add New Layers: - Ensure all new or updated data layers are added to the map\n",
    "\n",
    "‚ôªÔ∏è Overwrite Existing Map: - Overwrite: 005356185 THOR Master Construction Drawing Portal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9) üñ®Ô∏è Export Maps to the PDFs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Copy and paste** previous layout in ArcGIS Pro project:  005356185_THOR_Master_Construction_Drawing.aprx\n",
    "- üÜï **Update title** with new revision number\n",
    "- üìä **Update table** elements as required\n",
    "- Edit in the code:  \n",
    "    - *text_element = layout.listElements(\"TEXT_ELEMENT\", \"Text 27 - Revision Box - 01 Checked Initials **8**\")[0]*\n",
    "- üíª **Run the script** to export updated map books"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import arcpy\n",
    "import PyPDF2\n",
    "\n",
    "# Define the path to your ArcGIS Pro project\n",
    "new_version = \"11\"\n",
    "aprx_path = r\"\\\\WM20ocqu46ph01\\WF_Projects\\DK_THO\\4_OUTPUT\\_MCD\\005356185_THOR_Master_Construction_Drawing.aprx\"\n",
    "\n",
    "# Load the project\n",
    "aprx = arcpy.mp.ArcGISProject(aprx_path)\n",
    "\n",
    "# Specify the layout name\n",
    "layout_name = f\"005356185-{new_version} THOR Master Construction Drawing\"\n",
    "\n",
    "# Check if the specified layout exists\n",
    "layout = None\n",
    "for lyr in aprx.listLayouts():\n",
    "    if lyr.name == layout_name:\n",
    "        layout = lyr\n",
    "        break\n",
    "\n",
    "if layout is None:\n",
    "    raise ValueError(f\"Layout '{layout_name}' not found in the project.\")\n",
    "\n",
    "# Access the map series\n",
    "map_series = layout.mapSeries\n",
    "\n",
    "# Access the map frame to control layers\n",
    "map_frame = layout.listElements(\"MAPFRAME_ELEMENT\", \"Main Map Map Frame\")[0]\n",
    "map_ = map_frame.map\n",
    "\n",
    "# List all layers in the map to verify the layer name\n",
    "layers = map_.listLayers()\n",
    "print(\"Available layers:\")\n",
    "for layer in layers:\n",
    "    print(layer.name)\n",
    "\n",
    "# Access the map series layer \"DDP\"\n",
    "ddp_layer = None\n",
    "for layer in layers:\n",
    "    if layer.name == \"DDP\":\n",
    "        ddp_layer = layer\n",
    "        break\n",
    "\n",
    "if ddp_layer is None:\n",
    "    raise ValueError(\"Layer 'DDP' not found in the map.\")\n",
    "\n",
    "# Define the output directory for the map books\n",
    "output_dir = r\"\\\\WM20ocqu46ph01\\WF_Projects\\DK_THO\\4_OUTPUT\\_MCD\"\n",
    "\n",
    "# Define the definition queries for each map book\n",
    "definition_queries = [\"SCOPE = 'EEC'\", \"SCOPE = 'EAC'\", \"SCOPE = 'FOU'\", \"SCOPE = 'EOS'\"]\n",
    "\n",
    "# Define the text to update for each map book\n",
    "approved_by_texts = [\"DS\", \"AM\", \"RC/JC/OW\",\"NK\"]\n",
    "\n",
    "# Define the output file names for each map book\n",
    "output_files = [\"005356185-11 THOR Master Construction Drawing - EEC.pdf\",\n",
    "                \"005356185-11 THOR Master Construction Drawing - EAC.pdf\",\n",
    "                \"005356185-11 THOR Master Construction Drawing - FOU.pdf\",\n",
    "                \"005356185-11 THOR Master Construction Drawing - EOS.pdf\"]\n",
    "\n",
    "# Layers to be turned on for the first page only\n",
    "first_page_layers = [\"World Imagery (Clarity)\", \"Nearshore Bathymetry - 004896852-02-FUGG - THOR 2023 LIDAR SURVEY REPORT\", \"Hillshade Nearshore\"]\n",
    "\n",
    "# Export the first map book with layers on for the first page\n",
    "for i, definition_query in enumerate(definition_queries):\n",
    "    # Set the definition query for the map series layer\n",
    "    ddp_layer.definitionQuery = definition_query\n",
    "    \n",
    "    # Update the text element\n",
    "    text_element = layout.listElements(\"TEXT_ELEMENT\", \"Text 27 - Revision Box - 01 Checked Initials 8\")[0]\n",
    "    text_element.text = approved_by_texts[i]\n",
    "    \n",
    "    if i == 0:\n",
    "        # Turn on the specified layers for the first page of the first map book\n",
    "        for layer in layers:\n",
    "            if layer.name in first_page_layers:\n",
    "                layer.visible = True\n",
    "        \n",
    "        # Export the first page of the first map book\n",
    "        first_page_path = output_dir + f\"\\\\{output_files[i].replace('.pdf', '_first_page.pdf')}\"\n",
    "        map_series.exportToPDF(first_page_path, multiple_files=\"PDF_SINGLE_FILE\", resolution=100, page_range_type=\"RANGE\", page_range_string=\"1\")\n",
    "        \n",
    "        # Turn off the specified layers for the rest of the pages\n",
    "        for layer in layers:\n",
    "            if layer.name in first_page_layers:\n",
    "                layer.visible = False\n",
    "        \n",
    "        # Export the rest of the pages of the first map book (pages 2 to 35)\n",
    "        remaining_pages_path = output_dir + f\"\\\\{output_files[i].replace('.pdf', '_remaining_pages.pdf')}\"\n",
    "        map_series.exportToPDF(remaining_pages_path, multiple_files=\"PDF_SINGLE_FILE\", resolution=100, page_range_type=\"RANGE\", page_range_string=\"2-35\")\n",
    "        \n",
    "        # Merge the first page and the remaining pages into a single PDF\n",
    "        merger = PyPDF2.PdfFileMerger()\n",
    "        merger.append(first_page_path)\n",
    "        merger.append(remaining_pages_path)\n",
    "        merger.write(output_dir + f\"\\\\{output_files[i]}\")\n",
    "        merger.close()\n",
    "    else:\n",
    "        # Ensure the specified layers are off for the other map books\n",
    "        for layer in layers:\n",
    "            if layer.name in first_page_layers:\n",
    "                layer.visible = False\n",
    "        \n",
    "        # Export the entire map book\n",
    "        map_series.exportToPDF(output_dir + f\"\\\\{output_files[i]}\", multiple_files=\"PDF_SINGLE_FILE\", resolution=100)\n",
    "\n",
    "print(\"Map books exported successfully with updated text elements and 100 DPI resolution!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### XXX) Add ANY LAYER  to MCD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### ‚úÖ Update LAYER Field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import arcpy\n",
    "\n",
    "# === Path to feature class ===\n",
    "gdb_path = r\"\\\\WM20ocqu46ph01\\WF_Projects\\DK_THO\\2_FINAL\\VESSELS\\VESSELS.gdb\"\n",
    "name_FC = \"DK_THO_JB115_JackUpBarge_pt_UTM32N_v0\"\n",
    "fc = f\"{gdb_path}\\\\{name_FC}\"\n",
    "\n",
    "# === Add LAYER field if missing ===\n",
    "if \"Layer\" not in [f.name for f in arcpy.ListFields(fc)]:\n",
    "    arcpy.AddField_management(fc, \"LAYER\", \"TEXT\")\n",
    "    print(\"üÜï Field 'LAYER' added.\")\n",
    "else:\n",
    "    print(\"‚úÖ Field 'LAYER' already exists.\")\n",
    "\n",
    "# === Layer mapping ===\n",
    "layer_map = {\n",
    "    \"JUB Install\":               \"VESSEL - As Planned JUB Mooring Plan Installation\", \n",
    "    \"JUB Stand Off\":             \"VESSEL - As Planned JUB Mooring Plan Standoff\",\n",
    "    \"Mooring wire Installation\": \"VESSEL - As Planned JUB Mooring Plan Installation\",\n",
    "    \"Mooring wire Stand Off\":    \"VESSEL - As Planned JUB Mooring Plan Standoff\",\n",
    "}\n",
    "\n",
    "# === Update LAYER field ===\n",
    "with arcpy.da.UpdateCursor(fc, [\"LAYER\"]) as cursor:\n",
    "    for row in cursor:\n",
    "        original = row[0]\n",
    "        row[0] = layer_map.get(row[0], row[0])\n",
    "        if row[0] != original:\n",
    "            print(f\"üîÅ LAYER updated: '{original}' ‚ûù '{row[0]}'\")\n",
    "        cursor.updateRow(row)\n",
    "\n",
    "print(\"‚úÖ Section 1 complete: LAYER field updated.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### ‚úÖ Update SYMBOL Field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdb_path = r\"\\\\WM20ocqu46ph01\\WF_Projects\\DK_THO\\2_FINAL\\VESSELS\\VESSELS.gdb\"\n",
    "name_FC = \"DK_THO_JB115_JackUpBarge_pt_UTM32N_v0\"\n",
    "fc = f\"{gdb_path}\\\\{name_FC}\"\n",
    "\n",
    "# === Add SYMBOL field if missing ===\n",
    "if \"SYMBOL\" not in [f.name for f in arcpy.ListFields(fc)]:\n",
    "    arcpy.AddField_management(fc, \"SYMBOL\", \"TEXT\")\n",
    "    print(\"üÜï Field 'SYMBOL' added.\")\n",
    "else:\n",
    "    print(\"‚úÖ Field 'SYMBOL' already exists.\")\n",
    "\n",
    "# === Symbol mapping ===\n",
    "symbol_map = {\n",
    "    \"VESSEL - As Planned JUB Mooring Plan Installation\": \"As Planned JUB Mooring Installation\",\n",
    "    \"VESSEL - As Planned JUB Mooring Plan Standoff\":     \"As Planned JUB Mooring Standoff\",\n",
    "}\n",
    "\n",
    "# === Update SYMBOL field from LAYER ===\n",
    "with arcpy.da.UpdateCursor(fc, [\"LAYER\", \"SYMBOL\"]) as cursor:\n",
    "    for row in cursor:\n",
    "        original = row[1]\n",
    "        row[1] = row[0]  # Default: SYMBOL = LAYER\n",
    "        # row[1] = symbol_map.get(row[1], row[1])  # Override if match found\n",
    "        #if row[1] != original:\n",
    "        #    print(f\"üé® SYMBOL updated: '{original}' ‚ûù '{row[1]}'\")\n",
    "        cursor.updateRow(row)\n",
    "\n",
    "print(\"‚úÖ Section 2 complete: SYMBOL field updated.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### ‚úÖ Delete a Field from a Feature Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdb_path = r\"\\\\WM20ocqu46ph01\\WF_Projects\\DK_THO\\2_FINAL\\VESSELS\\VESSELS.gdb\"\n",
    "name_FC = \"DK_THO_JB115_JackUpBarge_pt_UTM32N_v0\"\n",
    "fc = f\"{gdb_path}\\\\{name_FC}\"\n",
    "\n",
    "# Field name to delete\n",
    "field_to_delete = \"Entity\"\n",
    "\n",
    "# Get a list of field names\n",
    "field_names = [field.name for field in arcpy.ListFields(fc)]\n",
    "\n",
    "# Check if the field exists and delete it\n",
    "if field_to_delete in field_names:\n",
    "    arcpy.DeleteField_management(fc, field_to_delete)\n",
    "    print(f\"üóëÔ∏è Field '*{field_to_delete}*' deleted from *{fc}*.\")\n",
    "else:\n",
    "    print(f\"‚ÑπÔ∏è Field '*{field_to_delete}*' does not exist in *{fc}*.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ArcGISPro",
   "language": "Python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
